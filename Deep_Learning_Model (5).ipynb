{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#                 Internship Task\n",
        "\n",
        "---\n",
        "\n",
        "###  Task Title: **Comparative Study of Deep Learning Models on MNIST Dataset**\n",
        "\n",
        "\n",
        "\n",
        "##  Task Overview\n",
        "**Section 1**:   Dataset Loading & Preprocessing   \n",
        "**Section 2**:   LeNet Model – Training & Evaluation on MNIST   \n",
        "**Section 3**:   ResNet Model – Training & Evaluation on MNIST  \n",
        "**Section 4**:   VGG16 Model – Training & Evaluation on MNIST  \n",
        "**Section 5**:   Transformer Model – Training & Evaluation on MNIST  \n"
      ],
      "metadata": {
        "id": "qAPVIlZmRDCO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4i65NiHTICF",
        "outputId": "67dcc14f-8745-4f56-fb93-7ac3010045e7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Section 1: Dataset Loading & Preprocessing"
      ],
      "metadata": {
        "id": "3VHxW_HgLWtR"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "waKDb8vGW2mn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import struct\n",
        "\n",
        "def load_images(filename):\n",
        "   with open(filename,'rb') as f:\n",
        "\n",
        "    magic, num,rows,cols = struct.unpack('>IIII' ,f.read(16))\n",
        "    images = np.frombuffer(f.read(), dtype = np.uint8)\n",
        "    images = images.reshape(num, rows, cols,1)\n",
        "    return images.astype(np.float32) /255.0\n"
      ],
      "metadata": {
        "id": "xsgC-qI3Tpz-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_labels(filename):\n",
        "  with open(filename, 'rb') as f:\n",
        "    magics, num = struct.unpack('>II', f.read(8))\n",
        "    labels = np.frombuffer(f.read(), dtype = np.uint8)\n",
        "    return labels"
      ],
      "metadata": {
        "id": "cRyfBgYDW5KB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = '/content/drive/MyDrive/mnist_data'\n",
        "\n",
        "x_train = load_images(f'{base_path}/train-images-idx3-ubyte/train-images-idx3-ubyte')\n",
        "y_train = load_labels(f'{base_path}/train-labels-idx1-ubyte/train-labels-idx1-ubyte')\n",
        "x_test = load_images(f'{base_path}/t10k-images-idx3-ubyte/t10k-images-idx3-ubyte')\n",
        "y_test = load_labels(f'{base_path}/t10k-labels-idx1-ubyte/t10k-labels-idx1-ubyte')\n"
      ],
      "metadata": {
        "id": "rhGpZ6QHXuq_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train shapes:\", x_train.shape, y_train.shape)\n",
        "print(\"Test shapes:\", x_test.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdzxQQIacb7I",
        "outputId": "070cf26c-70a9-4184-9cbc-b948e56a2530"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shapes: (60000, 28, 28, 1) (60000,)\n",
            "Test shapes: (10000, 28, 28, 1) (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Section 2: LeNet Model – Training & Evaluation on MNIST"
      ],
      "metadata": {
        "id": "MUIAGzz7K7KT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score"
      ],
      "metadata": {
        "id": "Rw6nT9NDcX4N"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#LeNet model architecture\n",
        "def create_lenet():\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=(28,28,1)),\n",
        "        layers.Conv2D(6,kernel_size=5,activation='relu',padding='same'),\n",
        "        layers.AveragePooling2D(pool_size = 2),\n",
        "        layers.Conv2D(16,kernel_size = 5, activation = 'relu'),\n",
        "        layers.AveragePooling2D(pool_size = 2),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(120, activation = 'relu'),\n",
        "        layers.Dense(84, activation = 'relu'),\n",
        "        layers.Dense(10, activation  = 'softmax')\n",
        "\n",
        "\n",
        "                             ])\n",
        "    return model"
      ],
      "metadata": {
        "id": "nAr2eKH6dI2h"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lenet = create_lenet()\n",
        "lenet.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics = ['accuracy'])\n"
      ],
      "metadata": {
        "id": "G4mC67m6finC"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Training\n",
        "lenet.fit(x_train, y_train, epochs = 25, batch_size = 64, validation_split = 0.1)\n",
        "test_loss, test_acc = lenet.evaluate(x_test, y_test, verbose = 0)\n",
        "print(f\"\\n LeNet Test Accuracy: {test_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApSp0Sl8g4Fb",
        "outputId": "93c6dbcd-d1e2-4822-fab4-545ae5c3b46f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.8211 - loss: 0.6184 - val_accuracy: 0.9755 - val_loss: 0.0825\n",
            "Epoch 2/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9724 - loss: 0.0916 - val_accuracy: 0.9808 - val_loss: 0.0640\n",
            "Epoch 3/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9809 - loss: 0.0612 - val_accuracy: 0.9848 - val_loss: 0.0521\n",
            "Epoch 4/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9854 - loss: 0.0447 - val_accuracy: 0.9845 - val_loss: 0.0513\n",
            "Epoch 5/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9881 - loss: 0.0366 - val_accuracy: 0.9880 - val_loss: 0.0410\n",
            "Epoch 6/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9903 - loss: 0.0313 - val_accuracy: 0.9870 - val_loss: 0.0437\n",
            "Epoch 7/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9918 - loss: 0.0261 - val_accuracy: 0.9908 - val_loss: 0.0341\n",
            "Epoch 8/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9928 - loss: 0.0218 - val_accuracy: 0.9893 - val_loss: 0.0348\n",
            "Epoch 9/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9941 - loss: 0.0178 - val_accuracy: 0.9912 - val_loss: 0.0349\n",
            "Epoch 10/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9951 - loss: 0.0154 - val_accuracy: 0.9903 - val_loss: 0.0350\n",
            "Epoch 11/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9953 - loss: 0.0147 - val_accuracy: 0.9888 - val_loss: 0.0393\n",
            "Epoch 12/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9953 - loss: 0.0133 - val_accuracy: 0.9888 - val_loss: 0.0390\n",
            "Epoch 13/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9966 - loss: 0.0110 - val_accuracy: 0.9917 - val_loss: 0.0355\n",
            "Epoch 14/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9973 - loss: 0.0092 - val_accuracy: 0.9877 - val_loss: 0.0537\n",
            "Epoch 15/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9967 - loss: 0.0093 - val_accuracy: 0.9895 - val_loss: 0.0419\n",
            "Epoch 16/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9965 - loss: 0.0102 - val_accuracy: 0.9903 - val_loss: 0.0431\n",
            "Epoch 17/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9975 - loss: 0.0081 - val_accuracy: 0.9900 - val_loss: 0.0456\n",
            "Epoch 18/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9975 - loss: 0.0075 - val_accuracy: 0.9898 - val_loss: 0.0520\n",
            "Epoch 19/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9973 - loss: 0.0074 - val_accuracy: 0.9907 - val_loss: 0.0429\n",
            "Epoch 20/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9979 - loss: 0.0067 - val_accuracy: 0.9903 - val_loss: 0.0436\n",
            "Epoch 21/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9980 - loss: 0.0058 - val_accuracy: 0.9912 - val_loss: 0.0396\n",
            "Epoch 22/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0034 - val_accuracy: 0.9912 - val_loss: 0.0464\n",
            "Epoch 23/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9978 - loss: 0.0064 - val_accuracy: 0.9912 - val_loss: 0.0429\n",
            "Epoch 24/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9980 - loss: 0.0056 - val_accuracy: 0.9915 - val_loss: 0.0397\n",
            "Epoch 25/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9978 - loss: 0.0060 - val_accuracy: 0.9913 - val_loss: 0.0483\n",
            "\n",
            " LeNet Test Accuracy: 0.9913\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Generate Prediction\n",
        "y_pred = lenet.predict(x_test).argmax(axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPSYZBJJicf6",
        "outputId": "bd0e26e4-7e15-4f0c-a6bc-9a92d4cbefb2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n LeNet Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, digits=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1hFFikujDiA",
        "outputId": "23d57e7a-0197-4320-a98c-8f2b2304284c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " LeNet Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9889    0.9980    0.9934       980\n",
            "           1     0.9956    0.9947    0.9952      1135\n",
            "           2     0.9942    0.9903    0.9922      1032\n",
            "           3     0.9844    0.9980    0.9912      1010\n",
            "           4     0.9928    0.9878    0.9903       982\n",
            "           5     0.9877    0.9877    0.9877       892\n",
            "           6     0.9937    0.9854    0.9895       958\n",
            "           7     0.9922    0.9903    0.9912      1028\n",
            "           8     0.9938    0.9867    0.9902       974\n",
            "           9     0.9891    0.9931    0.9911      1009\n",
            "\n",
            "    accuracy                         0.9913     10000\n",
            "   macro avg     0.9912    0.9912    0.9912     10000\n",
            "weighted avg     0.9913    0.9913    0.9913     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Section 3: ResNet  Model – Training & Evaluation on MNIST"
      ],
      "metadata": {
        "id": "ngOTAA5fK_MK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def residual_block(x, filters, kernel_size=3):\n",
        "    shortcut = x\n",
        "    x = layers.Conv2D(filters, kernel_size, padding='same', activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(filters, kernel_size, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "\n",
        "\n",
        " # Add skip connection\n",
        "    x = layers.add([x, shortcut])\n",
        "    x = layers.Activation('relu')(x)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "H6Iu_P3vkAav"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_resnet_mnist(input_shape=(28, 28, 1), num_classes=10):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    x = layers.Conv2D(32, 3, padding='same', activation='relu')(inputs)\n",
        "    x = residual_block(x, 32)\n",
        "    x = layers.MaxPooling2D()(x)\n",
        "\n",
        "    x = residual_block(x, 32)\n",
        "    x = layers.MaxPooling2D()(x)\n",
        "\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "    return model"
      ],
      "metadata": {
        "id": "1vaKFn-UqQ-a"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet = create_resnet_mnist()\n",
        "resnet.compile(optimizer='adam',\n",
        "               loss='sparse_categorical_crossentropy',\n",
        "               metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "5dxsGnEpUeR7"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "resnet.fit(x_train, y_train, epochs=25, batch_size=64, validation_split=0.1)\n",
        "\n",
        "\n",
        "test_loss, test_acc = resnet.evaluate(x_test, y_test, verbose=0)\n",
        "print(f\"\\nResNet Test Accuracy: {test_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FWpvqWeUior",
        "outputId": "941344fc-e8bb-4d1c-c6a5-4223016f40b3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 12ms/step - accuracy: 0.8871 - loss: 0.4113 - val_accuracy: 0.9638 - val_loss: 0.1203\n",
            "Epoch 2/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9837 - loss: 0.0532 - val_accuracy: 0.9900 - val_loss: 0.0404\n",
            "Epoch 3/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.9887 - loss: 0.0372 - val_accuracy: 0.9913 - val_loss: 0.0308\n",
            "Epoch 4/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9906 - loss: 0.0288 - val_accuracy: 0.9895 - val_loss: 0.0383\n",
            "Epoch 5/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9928 - loss: 0.0226 - val_accuracy: 0.9882 - val_loss: 0.0468\n",
            "Epoch 6/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9940 - loss: 0.0191 - val_accuracy: 0.9933 - val_loss: 0.0284\n",
            "Epoch 7/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.9948 - loss: 0.0158 - val_accuracy: 0.9907 - val_loss: 0.0343\n",
            "Epoch 8/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9958 - loss: 0.0128 - val_accuracy: 0.9933 - val_loss: 0.0288\n",
            "Epoch 9/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9950 - loss: 0.0139 - val_accuracy: 0.9922 - val_loss: 0.0329\n",
            "Epoch 10/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9965 - loss: 0.0100 - val_accuracy: 0.9927 - val_loss: 0.0377\n",
            "Epoch 11/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9965 - loss: 0.0091 - val_accuracy: 0.9923 - val_loss: 0.0256\n",
            "Epoch 12/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9977 - loss: 0.0070 - val_accuracy: 0.9923 - val_loss: 0.0339\n",
            "Epoch 13/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9968 - loss: 0.0096 - val_accuracy: 0.9923 - val_loss: 0.0331\n",
            "Epoch 14/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.9980 - loss: 0.0065 - val_accuracy: 0.9935 - val_loss: 0.0295\n",
            "Epoch 15/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9984 - loss: 0.0049 - val_accuracy: 0.9928 - val_loss: 0.0336\n",
            "Epoch 16/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.9973 - loss: 0.0070 - val_accuracy: 0.9915 - val_loss: 0.0478\n",
            "Epoch 17/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9981 - loss: 0.0067 - val_accuracy: 0.9938 - val_loss: 0.0347\n",
            "Epoch 18/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9992 - loss: 0.0021 - val_accuracy: 0.9923 - val_loss: 0.0367\n",
            "Epoch 19/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9974 - loss: 0.0073 - val_accuracy: 0.9918 - val_loss: 0.0414\n",
            "Epoch 20/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9982 - loss: 0.0053 - val_accuracy: 0.9870 - val_loss: 0.0657\n",
            "Epoch 21/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.9987 - loss: 0.0034 - val_accuracy: 0.9933 - val_loss: 0.0357\n",
            "Epoch 22/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9980 - loss: 0.0052 - val_accuracy: 0.9932 - val_loss: 0.0372\n",
            "Epoch 23/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9991 - loss: 0.0032 - val_accuracy: 0.9910 - val_loss: 0.0500\n",
            "Epoch 24/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9982 - loss: 0.0053 - val_accuracy: 0.9902 - val_loss: 0.0498\n",
            "Epoch 25/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9992 - loss: 0.0027 - val_accuracy: 0.9905 - val_loss: 0.0457\n",
            "\n",
            "ResNet Test Accuracy: 0.9911\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "y_pred = resnet.predict(x_test).argmax(axis=1)\n",
        "print(\"\\nResNet Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, digits=4))\n",
        "\n",
        "\n",
        "resnet_metrics = {\n",
        "    \"accuracy\": accuracy_score(y_test, y_pred),\n",
        "    \"precision\": precision_score(y_test, y_pred, average='weighted'),\n",
        "    \"recall\": recall_score(y_test, y_pred, average='weighted')\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEMnRYY9UrlH",
        "outputId": "05b09b76-96ab-4977-f74d-5bb2c2dddbdd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n",
            "\n",
            "ResNet Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9959    0.9949    0.9954       980\n",
            "           1     0.9887    1.0000    0.9943      1135\n",
            "           2     0.9971    0.9903    0.9937      1032\n",
            "           3     0.9796    0.9970    0.9882      1010\n",
            "           4     0.9939    0.9898    0.9918       982\n",
            "           5     0.9866    0.9888    0.9877       892\n",
            "           6     0.9958    0.9906    0.9932       958\n",
            "           7     0.9913    0.9961    0.9937      1028\n",
            "           8     0.9858    0.9959    0.9908       974\n",
            "           9     0.9969    0.9663    0.9814      1009\n",
            "\n",
            "    accuracy                         0.9911     10000\n",
            "   macro avg     0.9911    0.9910    0.9910     10000\n",
            "weighted avg     0.9912    0.9911    0.9911     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Section 4: VGG16  Model – Training & Evaluation on MNIST"
      ],
      "metadata": {
        "id": "zaq40NdJLKtJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_vgg_mnist(input_shape=(32, 32, 3), num_classes=10):\n",
        "    model = models.Sequential()\n",
        "\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(512, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "9FxSGJRzKdya"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_vgg = tf.image.resize(x_train, [32, 32])\n",
        "x_train_vgg = tf.image.grayscale_to_rgb(x_train_vgg)\n",
        "\n",
        "x_test_vgg = tf.image.resize(x_test, [32, 32])\n",
        "x_test_vgg = tf.image.grayscale_to_rgb(x_test_vgg)"
      ],
      "metadata": {
        "id": "zzQuJDfDUwn4"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and compile VGG model\n",
        "vgg = create_vgg_mnist()\n",
        "vgg.compile(optimizer='adam',\n",
        "            loss='sparse_categorical_crossentropy',\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "\n",
        "vgg.fit(x_train_vgg, y_train, epochs=25, batch_size=64, validation_split=0.1)\n",
        "\n",
        "\n",
        "test_loss, test_acc = vgg.evaluate(x_test_vgg, y_test, verbose=0)\n",
        "print(f\"\\nVGG16-style Test Accuracy: {test_acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzK82_FKUy75",
        "outputId": "1939b399-88bc-4494-9822-02feea222d6e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - accuracy: 0.9062 - loss: 0.2923 - val_accuracy: 0.9865 - val_loss: 0.0469\n",
            "Epoch 2/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9861 - loss: 0.0481 - val_accuracy: 0.9920 - val_loss: 0.0323\n",
            "Epoch 3/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9909 - loss: 0.0308 - val_accuracy: 0.9923 - val_loss: 0.0306\n",
            "Epoch 4/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9922 - loss: 0.0231 - val_accuracy: 0.9927 - val_loss: 0.0294\n",
            "Epoch 5/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9933 - loss: 0.0196 - val_accuracy: 0.9918 - val_loss: 0.0365\n",
            "Epoch 6/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9951 - loss: 0.0153 - val_accuracy: 0.9918 - val_loss: 0.0407\n",
            "Epoch 7/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9953 - loss: 0.0151 - val_accuracy: 0.9920 - val_loss: 0.0433\n",
            "Epoch 8/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9959 - loss: 0.0124 - val_accuracy: 0.9923 - val_loss: 0.0421\n",
            "Epoch 9/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9962 - loss: 0.0116 - val_accuracy: 0.9940 - val_loss: 0.0275\n",
            "Epoch 10/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9971 - loss: 0.0091 - val_accuracy: 0.9927 - val_loss: 0.0454\n",
            "Epoch 11/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9974 - loss: 0.0085 - val_accuracy: 0.9918 - val_loss: 0.0373\n",
            "Epoch 12/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9971 - loss: 0.0095 - val_accuracy: 0.9913 - val_loss: 0.0423\n",
            "Epoch 13/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9970 - loss: 0.0083 - val_accuracy: 0.9942 - val_loss: 0.0419\n",
            "Epoch 14/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9971 - loss: 0.0098 - val_accuracy: 0.9935 - val_loss: 0.0331\n",
            "Epoch 15/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9983 - loss: 0.0043 - val_accuracy: 0.9932 - val_loss: 0.0394\n",
            "Epoch 16/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9974 - loss: 0.0076 - val_accuracy: 0.9933 - val_loss: 0.0377\n",
            "Epoch 17/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9982 - loss: 0.0064 - val_accuracy: 0.9940 - val_loss: 0.0322\n",
            "Epoch 18/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9981 - loss: 0.0064 - val_accuracy: 0.9928 - val_loss: 0.0528\n",
            "Epoch 19/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9981 - loss: 0.0064 - val_accuracy: 0.9927 - val_loss: 0.0483\n",
            "Epoch 20/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9984 - loss: 0.0048 - val_accuracy: 0.9950 - val_loss: 0.0397\n",
            "Epoch 21/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9985 - loss: 0.0054 - val_accuracy: 0.9940 - val_loss: 0.0478\n",
            "Epoch 22/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9983 - loss: 0.0063 - val_accuracy: 0.9945 - val_loss: 0.0396\n",
            "Epoch 23/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9985 - loss: 0.0062 - val_accuracy: 0.9928 - val_loss: 0.0684\n",
            "Epoch 24/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.9985 - loss: 0.0055 - val_accuracy: 0.9938 - val_loss: 0.0398\n",
            "Epoch 25/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.9987 - loss: 0.0035 - val_accuracy: 0.9953 - val_loss: 0.0466\n",
            "\n",
            "VGG16-style Test Accuracy: 0.9949\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "y_pred = vgg.predict(x_test_vgg).argmax(axis=1)\n",
        "print(\"\\n VGG16-style Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, digits=4))\n",
        "\n",
        "\n",
        "# Store metrics\n",
        "vgg_metrics = {\n",
        "    \"accuracy\": accuracy_score(y_test, y_pred),\n",
        "    \"precision\": precision_score(y_test, y_pred, average='weighted'),\n",
        "    \"recall\": recall_score(y_test, y_pred, average='weighted')\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMNF_JcsU1nK",
        "outputId": "d0f25166-d22d-43d6-d0db-ee4d74dd768c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\n",
            " VGG16-style Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9969    0.9990    0.9980       980\n",
            "           1     0.9982    0.9965    0.9974      1135\n",
            "           2     0.9971    0.9922    0.9947      1032\n",
            "           3     0.9921    0.9970    0.9946      1010\n",
            "           4     0.9939    0.9959    0.9949       982\n",
            "           5     0.9944    0.9933    0.9938       892\n",
            "           6     0.9937    0.9927    0.9932       958\n",
            "           7     0.9903    0.9981    0.9942      1028\n",
            "           8     0.9949    0.9969    0.9959       974\n",
            "           9     0.9970    0.9871    0.9920      1009\n",
            "\n",
            "    accuracy                         0.9949     10000\n",
            "   macro avg     0.9949    0.9949    0.9949     10000\n",
            "weighted avg     0.9949    0.9949    0.9949     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Section 5: Transformer  Model – Training & Evaluation on MNIST\n"
      ],
      "metadata": {
        "id": "9thu3VgWLzVp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score"
      ],
      "metadata": {
        "id": "rhgeVs74VDnx"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#parameters\n",
        "\n",
        "NUM_CLASSES = 10\n",
        "D_MODEL = 64\n",
        "NUM_HEADS = 4\n",
        "FF_DIM = 128\n",
        "NUM_LAYERS = 4\n",
        "SEQ_LENGTH = 28\n",
        "FEATURES = 28"
      ],
      "metadata": {
        "id": "XKezn8aQVFHU"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Positional Encoding Layer\n",
        "class PositionalEncoding(layers.Layer):\n",
        "    def __init__(self, seq_len, d_model):\n",
        "        super().__init__()\n",
        "        self.pos_encoding = self.get_positional_encoding(seq_len, d_model)\n",
        "\n",
        "    def get_positional_encoding(self, position, d_model):\n",
        "        angle_rads = self.get_angles(\n",
        "            pos=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
        "            i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
        "            d_model=d_model\n",
        "        )\n",
        "        # Create sin and cos separately\n",
        "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
        "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
        "\n",
        "        # Interleave sin and cos\n",
        "        pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
        "        return pos_encoding[tf.newaxis, ...]\n",
        "\n",
        "    def get_angles(self, pos, i, d_model):\n",
        "        angle_rates = 1 / tf.pow(10000., (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
        "        return pos * angle_rates\n",
        "\n",
        "    def call(self, x):\n",
        "        return x + self.pos_encoding[:, :tf.shape(x)[1], :]\n"
      ],
      "metadata": {
        "id": "xEHqqk3sVJo6"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformer Encoder Block\n",
        "def transformer_encoder(inputs, d_model, num_heads, ff_dim):\n",
        "\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
        "    x = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)(x, x)\n",
        "    x = layers.Add()([x, inputs])\n",
        "\n",
        "\n",
        "    ffn = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "    ffn = layers.Dense(ff_dim, activation='relu')(ffn)\n",
        "    ffn = layers.Dense(d_model)(ffn)\n",
        "    return layers.Add()([ffn, x])"
      ],
      "metadata": {
        "id": "8gSanYXXVRPC"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformer model for MNIST\n",
        "def create_transformer_model():\n",
        "    inputs = layers.Input(shape=(SEQ_LENGTH, FEATURES))\n",
        "    x = layers.Dense(D_MODEL)(inputs)\n",
        "    x = PositionalEncoding(SEQ_LENGTH, D_MODEL)(x)\n",
        "\n",
        "    for _ in range(NUM_LAYERS):\n",
        "        x = transformer_encoder(x, D_MODEL, NUM_HEADS, FF_DIM)\n",
        "\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "    x = layers.Dropout(0.1)(x)\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    outputs = layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "    return models.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "\n",
        "\n",
        "transformer_model = create_transformer_model()\n",
        "transformer_model.compile(optimizer='adam',\n",
        "                          loss='sparse_categorical_crossentropy',\n",
        "                          metrics=['accuracy'])\n",
        "\n",
        "\n",
        "transformer_model.fit(x_train, y_train, epochs=25, batch_size=64, validation_split=0.1)\n",
        "\n",
        "\n",
        "test_loss, test_acc = transformer_model.evaluate(x_test, y_test, verbose=0)\n",
        "print(f\"\\nTransformer Test Accuracy: {test_acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6zQBlR2VW5i",
        "outputId": "37a7c1df-2206-4b2b-8385-5cd274136899"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 20ms/step - accuracy: 0.7185 - loss: 0.8005 - val_accuracy: 0.9732 - val_loss: 0.0905\n",
            "Epoch 2/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 9ms/step - accuracy: 0.9638 - loss: 0.1250 - val_accuracy: 0.9713 - val_loss: 0.0946\n",
            "Epoch 3/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9677 - loss: 0.1016 - val_accuracy: 0.9827 - val_loss: 0.0601\n",
            "Epoch 4/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9757 - loss: 0.0827 - val_accuracy: 0.9770 - val_loss: 0.0760\n",
            "Epoch 5/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9770 - loss: 0.0753 - val_accuracy: 0.9772 - val_loss: 0.0674\n",
            "Epoch 6/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9796 - loss: 0.0686 - val_accuracy: 0.9790 - val_loss: 0.0653\n",
            "Epoch 7/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9808 - loss: 0.0613 - val_accuracy: 0.9818 - val_loss: 0.0586\n",
            "Epoch 8/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9821 - loss: 0.0577 - val_accuracy: 0.9795 - val_loss: 0.0613\n",
            "Epoch 9/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9838 - loss: 0.0529 - val_accuracy: 0.9852 - val_loss: 0.0488\n",
            "Epoch 10/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9840 - loss: 0.0519 - val_accuracy: 0.9837 - val_loss: 0.0573\n",
            "Epoch 11/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9854 - loss: 0.0464 - val_accuracy: 0.9812 - val_loss: 0.0643\n",
            "Epoch 12/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9843 - loss: 0.0510 - val_accuracy: 0.9845 - val_loss: 0.0539\n",
            "Epoch 13/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9841 - loss: 0.0488 - val_accuracy: 0.9887 - val_loss: 0.0414\n",
            "Epoch 14/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9866 - loss: 0.0404 - val_accuracy: 0.9843 - val_loss: 0.0482\n",
            "Epoch 15/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9873 - loss: 0.0419 - val_accuracy: 0.9873 - val_loss: 0.0426\n",
            "Epoch 16/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9871 - loss: 0.0404 - val_accuracy: 0.9875 - val_loss: 0.0465\n",
            "Epoch 17/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9876 - loss: 0.0391 - val_accuracy: 0.9907 - val_loss: 0.0357\n",
            "Epoch 18/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9892 - loss: 0.0331 - val_accuracy: 0.9883 - val_loss: 0.0443\n",
            "Epoch 19/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9894 - loss: 0.0324 - val_accuracy: 0.9847 - val_loss: 0.0526\n",
            "Epoch 20/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9902 - loss: 0.0329 - val_accuracy: 0.9873 - val_loss: 0.0412\n",
            "Epoch 21/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9898 - loss: 0.0316 - val_accuracy: 0.9888 - val_loss: 0.0426\n",
            "Epoch 22/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.9900 - loss: 0.0305 - val_accuracy: 0.9863 - val_loss: 0.0456\n",
            "Epoch 23/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9896 - loss: 0.0323 - val_accuracy: 0.9902 - val_loss: 0.0403\n",
            "Epoch 24/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.9906 - loss: 0.0273 - val_accuracy: 0.9880 - val_loss: 0.0405\n",
            "Epoch 25/25\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9916 - loss: 0.0260 - val_accuracy: 0.9852 - val_loss: 0.0543\n",
            "\n",
            "Transformer Test Accuracy: 0.9854\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction\n",
        "y_pred = transformer_model.predict(x_test).argmax(axis=1)\n",
        "print(\"\\nTransformer Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, digits=4))\n",
        "\n",
        "# Store metrics\n",
        "transformer_metrics = {\n",
        "    \"accuracy\": accuracy_score(y_test, y_pred),\n",
        "    \"precision\": precision_score(y_test, y_pred, average='weighted'),\n",
        "    \"recall\": recall_score(y_test, y_pred, average='weighted')\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Trl42EEdV0z7",
        "outputId": "0e6e82d3-9dfe-42d6-d250-fc7d0474ca3d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step\n",
            "\n",
            "Transformer Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9948    0.9816    0.9882       980\n",
            "           1     0.9956    0.9859    0.9907      1135\n",
            "           2     0.9846    0.9903    0.9874      1032\n",
            "           3     0.9920    0.9871    0.9896      1010\n",
            "           4     0.9878    0.9919    0.9898       982\n",
            "           5     0.9876    0.9821    0.9848       892\n",
            "           6     0.9753    0.9885    0.9819       958\n",
            "           7     0.9855    0.9893    0.9874      1028\n",
            "           8     0.9592    0.9908    0.9747       974\n",
            "           9     0.9909    0.9663    0.9784      1009\n",
            "\n",
            "    accuracy                         0.9854     10000\n",
            "   macro avg     0.9853    0.9854    0.9853     10000\n",
            "weighted avg     0.9855    0.9854    0.9854     10000\n",
            "\n"
          ]
        }
      ]
    }
  ]
}